
/*
 * Uploads training data to your OpenAI API account,
 * and starts training the model using the default training data.
 */
.arguments
   type:string
   model:string
   epochs:int
   batch_size:int
   learning_rate_multiplier:decimal
   prompt_loss_weight:decimal
.description:Uploads training data to your OpenAI API account, and starts training the model associated with the specified type according to the arguments specified
.type:internal

// Making sure user has access to invoked endpoint.
auth.ticket.verify:root

// Sanity checking invocation.
validators.mandatory:x:@.arguments/*/type
validators.mandatory:x:@.arguments/*/model

// Connecting to database.
data.connect:[generic|magic]

   // Selecting all snippets that have not been pushed of specified type.
   data.read
      table:ml_training_snippets
      columns
         prompt
         completion
      where
         and
            type.eq:x:@.arguments/*/type
            pushed.eq:int:0
      limit:-1

   // Buffer containing all snippets we're about to send to OpenAI API.
   .snippets

   // Looping through each result from above and creating training data.
   for-each:x:@data.read/*

      // Buffer for prompt and completion.
      .prompt
      .completion

      // Getting data into correct format.
      set-value:x:@.prompt
         strings.concat
            get-value:x:@.dp/#/*/prompt
            .:" ->"
      set-value:x:@.completion
         strings.concat
            get-value:x:@.dp/#/*/completion
            .:" END"

      // Adding currently iterated snippet to above buffer.
      unwrap:x:+/*/*/*
      add:x:@.snippets
         .
            .
               prompt:x:@.prompt
               completion:x:@.completion

   // Creating our Bearer token by reading our OpenAI configuration settings.
   .token
   set-value:x:@.token
      strings.concat
         .:"Bearer "
         config.get:"magic:openai:key"

   // File data buffer containing JSONL content.
   .file-data

   // Converting [.snippets] to JSON, for then to convert manually to JSONL.
   lambda2json:x:@.snippets/*
   set-value:x:@.file-data
      strings.replace:x:@lambda2json
         .:"},{"
         .:"}\n{"
   set-value:x:@.file-data
      strings.substring:x:@.file-data
         .:1
         math.subtract
            strings.length:x:@.file-data
            .:int:2

   // Creating a unique training data filename.
   .filename
   set-value:x:@.filename
      strings.concat
         .:"attachment; name=file; filename=\"training-file-"
         guid.new
         .:".jsonl"
         .:"\""
   
   // Uploading file to OpenAI.
   http.post:"https://api.openai.com/v1/files"
      headers
         Authorization:x:@.token
         Content-Type:multipart/form-data
      payload
         entity:application/jsonl
            headers
               Content-Disposition:x:@.filename
            content:x:@.file-data
         entity:text/plain
            headers
               Content-Disposition:"form-data; name=purpose"
            content:fine-tune
      convert:true

   // Sanity checking above invocation.
   if
      not
         and
            mte:x:@http.post
               .:int:200
            lt:x:@http.post
               .:int:300
      .lambda

         // Oops, error - Logging error and returning status 500 to caller.
         lambda2hyper:x:@http.post
         log.error:Something went wrong while invoking OpenAI
            error:x:@lambda2hyper
         response.status.set:500
         return
            message:Something went wrong as we invoked OpenAI API

   /*
    * Using uploaded file to create a fine tuning.
    * First getting the ID of the file as stored in OpenAI's servers.
    */
   .id
   set-value:x:@.id
      get-value:x:@http.post/*/content/*/id

   // Parametrising training session invocation.
   if
      and
         exists:x:@.arguments/*/epochs
         not-null:x:@.arguments/*/epochs
      .lambda
         add:x:@data.connect/*/http.post/[1,2]/*/payload
            get-nodes:x:@.arguments/*/epochs
   if
      and
         exists:x:@.arguments/*/batch_size
         not-null:x:@.arguments/*/batch_size
      .lambda
         add:x:@data.connect/*/http.post/[1,2]/*/payload
            get-nodes:x:@.arguments/*/batch_size
   if
      and
         exists:x:@.arguments/*/learning_rate_multiplier
         not-null:x:@.arguments/*/learning_rate_multiplier
      .lambda
         add:x:@data.connect/*/http.post/[1,2]/*/payload
            get-nodes:x:@.arguments/*/learning_rate_multiplier
   if
      and
         exists:x:@.arguments/*/prompt_loss_weight
         not-null:x:@.arguments/*/prompt_loss_weight
      .lambda
         add:x:@data.connect/*/http.post/[1,2]/*/payload
            get-nodes:x:@.arguments/*/prompt_loss_weight

   // Starting training session.
   http.post:"https://api.openai.com/v1/fine-tunes"
      headers
         Authorization:x:@.token
         Content-Type:application/json
      payload
         training_file:x:@.id
         model:x:@.arguments/*/model
         suffix:x:@.arguments/*/type
      convert:true

   // Sanity checking above invocation.
   if
      neq:x:@http.post
         .:int:200
      .lambda

         // Oops, error - Logging error and returning status 500 to caller.
         lambda2hyper:x:@http.post
         log.error:Something went wrong while invoking OpenAI
            error:x:@lambda2hyper
         response.status.set:500
         return
            message:Something went wrong as we started our training session

   // Logging that we've started training.
   get-count:x:@data.read/*
   log.info:Successfully started training of OpenAI model
      type:x:@.arguments/*/type
      snippets:x:@get-count
      base-model:x:@.arguments/*/model
      new-model-id:x:@http.post/*/content/*/id

   /*
    * Creating a task that repeats once every 30 seconds until training is completed,
    * for then to make sure we associate the new model with the specified type.
    */
   .task-id
   set-value:x:@.task-id
      strings.concat
         .:magic.openai.training-session.
         guid.new
   unwrap:x:./*/tasks.create/*/*/.task-id
   unwrap:x:./*/tasks.create/*/*/.model-id
   unwrap:x:./*/tasks.create/*/*/.type
   tasks.create:x:@.task-id
      repeats:30.seconds
      .lambda

         // Forward evaluated above.
         .task-id:x:@.lambda/@.task-id
         .model-id:x:@http.post/*/content/*/id
         .type:x:@.arguments/*/type

         // Checking model status using OpenAI API, making sure we parametrise Authorization header with token
         .token
         set-value:x:@.token
            strings.concat
               .:"Bearer "
               config.get:"magic:openai:key"
         strings.concat
            .:"https://api.openai.com/v1/fine-tunes/"
            get-value:x:@.model-id
         http.get:x:@strings.concat
            headers
               Authorization:x:@.token
            convert:true
         if
            and
               mte:x:@http.get
                  .:int:200
               lt:x:@http.get
                  .:int:300
            .lambda

               // Checking if job succeeded.
               if
                  eq:x:@http.get/*/content/*/status
                     .:succeeded
                  .lambda

                     // Training is done, updating type declaration with new model.
                     log.info:Training of OpenAI model completed successfully

                     // Updating type.
                     data.connect:[generic|magic]
                     
                        // Making sure we mark all snippets we used for training as pushed.
                        data.update
                           table:ml_types
                           values
                              model:x:@http.get/*/content/*/fine_tuned_model
                           where
                              and
                                 type.eq:x:@.type

                        // Marking all snippets we've sent as "pushed".
                        data.update
                           table:ml_training_snippets
                           values
                              pushed:int:1
                           where
                              and
                                 type.eq:x:@.type

                     // Deleting task
                     tasks.delete:x:@.task-id

                     // Signaling root users in the frontend
                     sockets.signal:magic.backend.message
                        roles:root
                        args
                           message:Training of your OpenAI model succeeded!
                           type:success


               else-if
                  eq:x:@http.get/*/content/*/status
                     .:failed
                  .lambda

                     // Training is done, and it FAILED!
                     log.error:Training of OpenAI model FAILED!!

                     // Deleting task
                     tasks.delete:x:@.task-id

                     // Signaling root users in the frontend
                     sockets.signal:magic.backend.message
                        roles:root
                        args
                           message:Training of your OpenAI model FAILED!
                           type:error

         else

            // Invocation failed
            lambda2hyper:x:@http.get
            log.error:Retrieving training session status from OpenAI failed
               result:x:@lambda2hyper


// Returning success to caller.
return
   result:success
